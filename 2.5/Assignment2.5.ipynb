{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# Load the InterPROscan output file into a Dask DataFrame\n",
    "filename = '/data/dataprocessing/interproscan/all_bacilli.tsv'\n",
    "df = dd.read_csv(filename, sep='\\t', dtype=str, header=None, names=[\"0\", \"1\", \"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.info(),\"\\n\",75*\"_\")\n",
    "print(df.describe(),\"\\n\",75*\"_\")\n",
    "print(\"nulls : \",df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique protein annotations\n",
    "unique_annotations = df['11'].nunique().compute(num_workers=16)\n",
    "\n",
    "print(\"Distinct protein annotations:\", unique_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of annotations per protein\n",
    "mean_annotations = df.groupby('1').size().mean().compute(num_workers=16)\n",
    "\n",
    "print(\"Average annotations per protein:\", mean_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split '|'\n",
    "go_terms = df['0'].str.split('|').explode()\n",
    "\n",
    "# Count most common GO term\n",
    "most_common_go_term = go_terms.value_counts().nlargest(1).compute().index[0]\n",
    "print(\"Most common GO Term:\", most_common_go_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of InterPRO features\n",
    "df['FeatureSize'] = df['7'].astype(int) - df['6'].astype(int)\n",
    "\n",
    "# Average size of InterPRO features\n",
    "average_size_feature = df['FeatureSize'].mean().compute(num_workers=16)\n",
    "\n",
    "# Rounded with two decimal places\n",
    "average_size_feature_formatted = \"{:.2f}\".format(average_size_feature)\n",
    "print(f\"Average size of InterPRO feature: {average_size_feature_formatted}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 most common InterPRO features\n",
    "top_10_interpro_features = df['1'].value_counts().nlargest(10).compute(num_workers=16)\n",
    "\n",
    "print(\"Top 10 most common InterPRO features:\")\n",
    "\n",
    "# Iterate over the top 10 features\n",
    "for index, feature_count in top_10_interpro_features.iteritems():\n",
    "    print(f\"Feature: {index}, Count: {feature_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the protein size from column '2'\n",
    "protein_size = df['2'].astype(int)\n",
    "\n",
    "# specify the similarity threshold (90-100% similarity)\n",
    "similar_size_threshold = 0.9\n",
    "\n",
    "# pick InterPRO features with similar size proteins\n",
    "similar_size_features = df[abs(df['FeatureSize'] - protein_size) / protein_size <= similar_size_threshold]\n",
    "\n",
    "# Find the top 10 most common InterPRO attributes within comparable-sized characteristics.\n",
    "top_10_similar_size_features = similar_size_features['1'].value_counts().nlargest(10).compute(num_workers=16)\n",
    "\n",
    "print(\"Top 10 most common InterPRO features with similar size:\")\n",
    "\n",
    "# Iterate over the top 10 similar size features and print each feature with its count\n",
    "for index, feature_count in top_10_similar_size_features.iteritems():\n",
    "    print(f\"Feature: {index}, Count: {feature_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Concatenate the textual annotations from columns '3', '4', '5', '11', and '12'\n",
    "text_annotations = df['3'] + ' ' + df['4'] + ' ' + df['5'] + df['11'] + df['12']\n",
    "\n",
    "# Convert the text annotations to lowercase, remove special characters, and normalize whitespaces\n",
    "text_annotations = text_annotations.str.lower().str.replace(r'[^a-zA-Z0-9\\s]', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "# frequency of each word\n",
    "word_counts = Counter(word for annotation in text_annotations for word in annotation.split())\n",
    "\n",
    "# top 10 most common words\n",
    "top_10_words = word_counts.most_common(10)\n",
    "\n",
    "for word, count in top_10_words:\n",
    "    print(word, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the top 10 least common word found in that annotation\n",
    "\n",
    "top_10_least_common_words = word_counts.most_common()[:-11:-1]\n",
    "\n",
    "for word, count in top_10_least_common_words:\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Select InterPRO features that are almost the same size as the protein itself\n",
    "protein_size = df['2'].astype(int)\n",
    "similar_size_threshold = 0.9  # 90-100% similarity\n",
    "similar_size_features = df[abs(df['FeatureSize'] - protein_size) / protein_size <= similar_size_threshold]\n",
    "\n",
    "# Get the textual annotation columns for the selected features\n",
    "text_annotations = similar_size_features['3'] + ' ' + similar_size_features['4'] + ' ' + similar_size_features['5'] + similar_size_features['11'] + similar_size_features['12']\n",
    "text_annotations = text_annotations.str.lower().str.replace(r'[^a-zA-Z0-9\\s]', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "# frequency of each word\n",
    "word_counts = Counter(word for annotation in text_annotations for word in annotation.split())\n",
    "\n",
    "# top 10 most common words\n",
    "top_10_words = word_counts.most_common(10)\n",
    "\n",
    "for word, count in top_10_words:\n",
    "    print(word, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient of correlation between protein size and number of features\n",
    "coefficient_of_correlation = df['2'].astype(int).corr(df['7'].astype(int) - df['6'].astype(int))\n",
    "coefficient_of_correlation_result = coefficient_of_correlation.compute(num_workers=16)\n",
    "print(\"Coefficient of correlation:\", coefficient_of_correlation_result)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
