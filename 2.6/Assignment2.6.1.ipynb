{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The article 'Software Engineering for Machine Learning: Characterizing and Detecting Mismatch in Machine-Learning Systems' by Lewis and Ozkaya (2021)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article \"Software Engineering for Machine Learning: Characterizing and Detecting Mismatch in Machine-Learning Systems\" by Lewis and Ozkaya discusses the challenges in developing and deploying ML-enabled systems and identifies different types of mismatches that can occur. The authors aim to create empirically validated practices and tools to support the software engineering of ML-enabled systems.\n",
    "\n",
    "\n",
    "1. Computing-resource mismatch: Poor system performance due to inadequate computing resources in the production environment. For example, if an ML model requires high computational power but the production environment lacks it, the system's performance will be compromised.\n",
    "\n",
    "2. Data-distribution mismatch: Reduced model accuracy due to differences between the training data and the production data. For instance, if an ML model is trained on a specific dataset, but the production data differs significantly, the model's performance will degrade.\n",
    "\n",
    "3. API mismatch: Difficulty integrating the ML component into the larger system due to differences in expected inputs and outputs. This can result in the need for extensive glue code to bridge the gaps.\n",
    "\n",
    "4. Test-data mismatch: Inability to properly test an ML component due to limited access to test data or inadequate understanding of the component. This can hinder effective testing and validation of the ML system.\n",
    "\n",
    "5. Monitoring mismatch: Inability of monitoring tools in the production environment to collect relevant metrics specific to ML components, such as model accuracy. This lack of ML-specific monitoring capabilities can make it challenging to assess the system's performance.\n",
    "6. Operational data: Mismatches in this category result from a lack of statistics on operational data. If the data used to train the model does not accurately represent the data in the production environment, the model's performance may be suboptimal.\n",
    "\n",
    "7. Training data: Mismatches here arise from a lack of details about data preparation pipelines. Without information on how the training data was derived from raw data, data scientists may face limitations in exploring alternative feature engineering techniques.\n",
    "\n",
    "The article highlights the importance of improved communication and the development of automated tools to detect and prevent these mismatches. The authors aim to create machine-readable descriptors that capture the necessary information to avoid mismatches and facilitate collaboration among stakeholders in ML-enabled system development. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The article 'Tackling Collaboration Challenges in the Development of ML-Enabled Systems' by Lewis (2023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article, the author discusses the challenges of collaboration in the development of ML-enabled systems and presents findings from a study on this topic. The study was conducted through interviews with professionals building ML-enabled systems and a literature review on software engineering for ML-enabled systems. The three main collaboration points identified are requirements and planning, training data, and product-model integration.\n",
    "\n",
    "1. **Requirements and Planning**: For requirements and planning, tensions arise between product requirements and model requirements. Recommendations include involving data scientists early in the process, adopting a parallel development trajectory for product and model teams, conducting ML training sessions for clients and product teams, and adopting more formal requirements documentation.\n",
    "\n",
    "Recommendations:\n",
    "- Involve data scientists early in the process to better understand ML capabilities.\n",
    "- Consider adopting a parallel development trajectory for product and model teams. \n",
    "\n",
    "2. **Training Data**: Disagreements often occur due to the lack of ownership, understanding, and coordination between the product team and the model team. Recommendations include planning for data collection and access to domain experts, adopting formal contracts specifying data quality and quantity expectations, clarifying expectations when working with a dedicated data team, and establishing data validation and monitoring infrastructure.\n",
    "\n",
    "Recommendations:\n",
    "- Plan and budget for data collection and access to domain experts.\n",
    "- Adopt a formal contract that specifies data quality and quantity expectations.\n",
    "- Employ a data validation and monitoring infrastructure early in the project. \n",
    "\n",
    "3. **Product-Model Integration**: This collaboration point involves close cooperation between data scientists and software engineers. Conflicts can arise due to differences in cultures, unclear processes and responsibilities, and different quality assurance approaches.\n",
    "\n",
    "Recommendations:\n",
    "- Define processes, responsibilities, and boundaries more carefully. \n",
    "- Encourage open communication and avoid siloing data scientists. \n",
    "\n",
    "4. **Quality Assurance for Model and Product**: Ensuring model adequacy and transparent evaluation, as well as responsibility for system testing, are challenges in this collaboration point.\n",
    "\n",
    "Recommendations:\n",
    "- Plan for structured feedback from the product engineering team to the model team. \n",
    "- Define clear quality requirements for model and product.\n",
    "\n",
    "The article concludes by emphasizing the importance of improving collaboration in ML-enabled system development. It suggests focusing on communication, documentation, engineering capabilities, and process alignment to facilitate effective collaboration between data scientists and software engineers."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
